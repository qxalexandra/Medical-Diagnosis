{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1512919,"sourceType":"datasetVersion","datasetId":611716}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport os \nimport cv2\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator  ","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:47:54.276647Z","iopub.execute_input":"2024-06-05T00:47:54.277413Z","iopub.status.idle":"2024-06-05T00:47:54.282692Z","shell.execute_reply.started":"2024-06-05T00:47:54.277378Z","shell.execute_reply":"2024-06-05T00:47:54.281661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imsize=64;  \ndatagen=False\ndataset='ocular'\n\n# poreluare etichetare in format df \nimport pandas as pd\nimport numpy as np \ndf = pd.read_csv(\"/kaggle/input/ocular-disease-recognition-odir5k/full_df.csv\")\ndf.shape[0]\n\n#etichetare clase \ndef has_normal(text):\n    if \"normal\" in text:\n        return 1\n    else:\n        return 0\ndef has_cataract(text):\n    if \"cataract\" in text:\n        return 1\n    else:\n        return 0\ndef has_diabetes(text):\n    if \"retinopathy\" in text:\n        return 1\n    else:\n        return 0\ndef has_glaucoma(text):\n    if \"glaucoma\" in text:\n        return 1\n    else:\n        return 0\ndef has_degeneration(text):\n    if \"age-related macular degeneration\" in text:\n        return 1\n    else:\n        return 0\ndef has_hypertension(text):\n    if \"hypertensive\" in text:\n        return 1\n    else:\n        return 0\ndef has_myopia(text):\n    if \"pathological myopia\" in text:\n        return 1\n    else:\n        return 0 \n\ndf[\"left_normal\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_normal(x))\ndf[\"right_normal\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_normal(x))\nleft_normal = df.loc[(df.N ==1) & (df.left_normal == 1)][\"Left-Fundus\"].values\nleft_normal\nright_normal = df.loc[(df.N ==1) & (df.right_normal == 1)][\"Right-Fundus\"].values\nright_normal\nprint(\"Number of images in left normal: {}\".format(len(left_normal)))\nprint(\"Number of images in right normal: {}\".format(len(right_normal)))\nprint()\n\n\ndf[\"left_cataract\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))\ndf[\"right_cataract\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_cataract(x))\nleft_cataract = df.loc[(df.C ==1) & (df.left_cataract == 1)][\"Left-Fundus\"].values\nleft_cataract\nright_cataract = df.loc[(df.C ==1) & (df.right_cataract == 1)][\"Right-Fundus\"].values\nright_cataract\nprint(\"Number of images in left cataract: {}\".format(len(left_cataract)))\nprint(\"Number of images in right cataract: {}\".format(len(right_cataract)))\nprint()\n\n\ndf[\"left_diabetes\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_diabetes(x))\ndf[\"right_diabetes\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_diabetes(x))\nleft_diabetes = df.loc[(df.D ==1) & (df.left_diabetes == 1)][\"Left-Fundus\"].values\nright_diabetes = df.loc[(df.D ==1) & (df.right_diabetes == 1)][\"Right-Fundus\"].values\ndiabetes_images = np.concatenate((left_diabetes, right_diabetes))\nprint(\"Number of images in left diabetes: {}\".format(len(left_diabetes)))\nprint(\"Number of images in right diabetes: {}\".format(len(right_diabetes)))\nprint()\n\n\ndf[\"left_glaucoma\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_glaucoma(x))\ndf[\"right_glaucoma\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_glaucoma(x))\nleft_glaucoma = df.loc[(df.G ==1) & (df.left_glaucoma == 1)][\"Left-Fundus\"].values\nleft_glaucoma\nright_glaucoma = df.loc[(df.G ==1) & (df.right_glaucoma == 1)][\"Right-Fundus\"].values\nright_glaucoma\nprint(\"Number of images in left glaucoma: {}\".format(len(left_glaucoma)))\nprint(\"Number of images in right glaucoma: {}\".format(len(right_glaucoma)))\nprint()\n\n\ndf[\"left_degeneration\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_degeneration(x))\ndf[\"right_degeneration\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_degeneration(x))\nleft_degeneration = df.loc[(df.A ==1) & (df.left_degeneration == 1)][\"Left-Fundus\"].values\nleft_degeneration\nright_degeneration = df.loc[(df.A ==1) & (df.right_degeneration == 1)][\"Right-Fundus\"].values\nright_degeneration\nprint(\"Number of images in left degeneration: {}\".format(len(left_degeneration)))\nprint(\"Number of images in right degeneration: {}\".format(len(right_degeneration)))\nprint()\n\n\ndf[\"left_myopia\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_myopia(x))\ndf[\"right_myopia\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_myopia(x))\nleft_myopia = df.loc[(df.M ==1) & (df.left_myopia == 1)][\"Left-Fundus\"].values\nleft_myopia\nright_myopia = df.loc[(df.M ==1) & (df.right_myopia == 1)][\"Right-Fundus\"].values\nright_myopia\nprint(\"Number of images in left myopia: {}\".format(len(left_myopia)))\nprint(\"Number of images in right myopia: {}\".format(len(right_myopia)))\nprint()\n\n\ndf[\"left_hypertension\"] = df[\"Left-Diagnostic Keywords\"].apply(lambda x: has_hypertension(x))\ndf[\"right_hypertension\"] = df[\"Right-Diagnostic Keywords\"].apply(lambda x: has_hypertension(x))\nleft_hypertension = df.loc[(df.H ==1) & (df.left_hypertension == 1)][\"Left-Fundus\"].values\nleft_hypertension\nright_hypertension = df.loc[(df.H ==1) & (df.right_hypertension == 1)][\"Right-Fundus\"].values\nright_hypertension\nprint(\"Number of images in left hypertension: {}\".format(len(left_hypertension)))\nprint(\"Number of images in right hypertension: {}\".format(len(right_hypertension)))\nprint()\n\n\nleft_abnormalities = df.loc[(df.C ==0) & (df.N ==0) & (df.D ==0) & (df.G ==0) & (df.A ==0)& (df.M ==0) & (df.H ==0)][\"Left-Fundus\"].sample(250,random_state=42).values\nleft_abnormalities\nright_abnormalities = df.loc[(df.C ==0) & (df.N ==0) & (df.D ==0) & (df.G ==0) & (df.A ==0)& (df.M ==0) & (df.H ==0) ][\"Right-Fundus\"].sample(250,random_state=42).values\nright_abnormalities\nprint(\"Number of images in left abnormalities: {}\".format(len(left_abnormalities)))\nprint(\"Number of images in right abnormalities: {}\".format(len(right_abnormalities)))\nprint()\n\n\ncataract = np.concatenate((left_cataract,right_cataract),axis=0)\nnormal = np.concatenate((left_normal,right_normal),axis=0)\nglaucoma = np.concatenate((left_glaucoma,right_glaucoma),axis=0)\ndiabetes = np.concatenate((left_diabetes,right_diabetes),axis=0)\ndegeneration = np.concatenate((left_degeneration,right_degeneration),axis=0)\nmyopia = np.concatenate((left_myopia,right_myopia),axis=0)\nhypertension = np.concatenate((left_hypertension,right_hypertension),axis=0)\nabnormalities = np.concatenate((left_abnormalities,right_abnormalities),axis=0)\n\nprint(\"Total cataract images: \",len(cataract))\nprint(\"Total normal images: \",len(normal))\nprint(\"Total galucoma images: \",len(glaucoma)) \nprint(\"Total diabetes images: \",len(diabetes)) \nprint(\"Total degeneration images: \",len(degeneration)) \nprint(\"Total myopia images: \",len(myopia))\nprint(\"Total hypertension images: \",len(hypertension)) \nprint(\"Total abnormalities images: \",len(abnormalities))\nprint()\n\ndef load_odir_data(Array_of_Images):\n    Images = []\n    Labels = []\n    count = -1\n    for i in Array_of_Images:\n        count += 1\n        print(count)\n        count1 = 0;\n        for j in i:\n            count1 += 1\n            #empty_Label = np.array([0,0,0,0])\n            empty_Label= np.zeros(num_classes)  # pentru un numar arbitrar de clase \n            if(j in os.listdir(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Testing Images/\")):\n                fileName = \"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Testing Images/\"+j\n            elif(j in os.listdir(\"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images/\")):\n                fileName = \"/kaggle/input/ocular-disease-recognition-odir5k/ODIR-5K/ODIR-5K/Training Images/\"+j\n            else:\n                fileName = \"/kaggle/input/ocular-disease-recognition-odir5k/preprocessed_images/\"+j\n            images = cv2.imread(fileName)\n#             print(images.shape)\n            images = cv2.resize(images, (imsize,imsize), interpolation = cv2.INTER_NEAREST)\n            Images.append(np.array(images))\n            empty_Label[count] = 1\n            Labels.append(empty_Label)\n            \n    return np.array(Images), np.array(Labels)\n\n#--- aici se face o alegere pe maximum de 8 clase (perf. mai proasta)\nmy_categories=[normal, cataract, glaucoma, myopia]  # 4 clase (se pot organiza oricum - cu 6 clase perf. e mai slaba )\n#my_categories=[normal, cataract, glaucoma, degeneration, myopia, diabetes]#, hypertension, abnormalities]  # 6 sau 8 clase \n#my_categories=[normal, cataract, myopia, diabetes] # \n\nnum_classes=len(my_categories)\nimport time as ti \nt1=ti.time()\nImages, Labels = load_odir_data(my_categories)\nt2=ti.time()\nprint('Durata creare baza de date: ', t2-t1, 'secunde',' Numar clase: ', num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:48:52.707050Z","iopub.execute_input":"2024-06-05T00:48:52.707486Z","iopub.status.idle":"2024-06-05T00:51:10.816851Z","shell.execute_reply.started":"2024-06-05T00:48:52.707447Z","shell.execute_reply":"2024-06-05T00:51:10.815774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(imsize,imsize,3)\nbatch_size=16\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(Images, Labels, test_size=0.3, random_state=42)\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255; x_test /=255  # scalare [0,1]\nprint('Numar clase: ',np.shape(y_train)[1])\nprint('Date intrare: ',input_shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:51:53.867763Z","iopub.execute_input":"2024-06-05T00:51:53.868607Z","iopub.status.idle":"2024-06-05T00:51:54.005888Z","shell.execute_reply.started":"2024-06-05T00:51:53.868566Z","shell.execute_reply":"2024-06-05T00:51:54.004835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# V-CNN MODEL","metadata":{}},{"cell_type":"code","source":"# V-CNN Versatile CNN model -\n# includes L-CNN, NL-CNN and XNL-CNN as particular cases.\n# The basic unit is the \"macro-layer\" as in the XNL-CNN but here one can independently choose the\n# filter size (fil) and\n# nonlinearity nl (0 means \"linear\" convolution)\n# It allows any number of additional dense layers e.g. hid=[] (no hidden dense) or hid =[100, 100] (two additional).\n# Copyright Radu and Ioana DOGARU - correspondence: radu.dogaru@upb.ro\n# Last update June 21, 2023\n# Code located at https://colab.research.google.com/github/radu-dogaru/V-CNN/\n#-------------------------------------------------------------------------------------------------\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adadelta, Adam, Nadam\n\n#--------------------------  ------------------------------\ndef create_v_cnn_model(input_shape, num_classes, flat=1, fil=[100,100,100,100], nl=[1,1,0,0], hid=[]):\n    # Note the number of elements in fil list (macrolayers) should be the same in nl list\n    # hid can be [] while if the are elements, additional dense layers are added in the output classifier\n\n    csize=3; stri=2; psiz=4; pad='same';\n    drop1=0.6  # Best value for CIFAR-100 after tuning in range 0.25 - 0.75 !\n\n    nfilmax=np.shape(np.array(fil))[0]\n    model = Sequential()\n    # First macrolayer - connected to input  ----------------\n    layer=0\n    if nl[layer]>0:\n        model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize), input_shape=input_shape ) )\n        model.add(Activation('relu'))\n        for nonlin in range(1,nl[0]):\n            model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )\n            model.add(Activation('relu'))\n\n        model.add(Conv2D(fil[0], padding=pad, kernel_size=(csize, csize) ) )\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))\n        model.add(Dropout(drop1))\n\n    else:\n        model.add(Conv2D(fil[0], padding=pad, kernel_size=(csize, csize), input_shape=input_shape ) )\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))\n        model.add(Dropout(drop1))\n    # The remaining  macro-layers\n\n    for layer in range(1,nfilmax):\n        #------------------ nonlin layers -----------------\n        for nonlin in range(nl[layer]):\n            model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )\n            model.add(Activation('relu'))\n\n        #----------------- default macrolayer output\n\n        model.add(Conv2D(fil[layer], padding=pad, kernel_size=(csize, csize)) )\n        model.add(BatchNormalization())\n        model.add(MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad))\n        model.add(Dropout(drop1))\n\n    # Exit classifier\n    # INPUT TO DENSE LAYER (FLATTEN - more data can overfit / GLOBAL - less data - may be a good choice )\n    if flat==1:\n        model.add(Flatten())  # alternanta cu GlobalAv ..\n    elif flat==0:\n        model.add(GlobalAveragePooling2D()) # pare sa fie mai Ok la cifar\n    nhid=np.shape(np.array(hid))[0]\n    if nhid>0:\n        for lay in range(nhid):\n            model.add(Dense(hid[lay], activation='relu'))\n            #model.add(Dropout(drop1))\n    model.add(Dense(num_classes, activation='softmax'))\n\n# END OF MODEL DESCRIPTION\n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(),\n        loss = 'categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:51:58.659638Z","iopub.execute_input":"2024-06-05T00:51:58.660050Z","iopub.status.idle":"2024-06-05T00:51:58.681020Z","shell.execute_reply.started":"2024-06-05T00:51:58.660014Z","shell.execute_reply":"2024-06-05T00:51:58.679792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Instantiere model V-CNN","metadata":{}},{"cell_type":"code","source":"myflat=0; myfil=[40,80,160,80,40]; mynl=[2,1,0,0,0]; myhid=[]   # aici se pot testa diferite alte valori \nmodel=create_v_cnn_model(input_shape, num_classes, flat=myflat, fil=myfil, nl=mynl, hid=myhid)\nmodel_name='VCNN_'+str(myflat)+'_'+str(myfil)+'_'+str(mynl)+'_'+str(myhid)\nprint(model_name)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T00:52:03.595026Z","iopub.execute_input":"2024-06-05T00:52:03.595696Z","iopub.status.idle":"2024-06-05T00:52:04.128942Z","shell.execute_reply.started":"2024-06-05T00:52:03.595662Z","shell.execute_reply":"2024-06-05T00:52:04.127909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NL-CNN MODEL","metadata":{}},{"cell_type":"code","source":"# Returns a precompiled model with a specific optimizer included \n#==============================================================================================\nfrom tensorflow.keras.models import Sequential\n#from keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.layers  import BatchNormalization\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\nfrom tensorflow.keras.layers import Conv2D, DepthwiseConv2D, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, SeparableConv2D  # straturi convolutionale si max-pooling \nfrom tensorflow.keras.optimizers import  SGD, Adadelta, Adam, Nadam\n\n\ndef create_nl_cnn_model(input_shape, num_classes, k=1.5,separ=0, flat=0, width=80, nl=(3,2), add_layer=0):\n  # Arguments: k - multiplication coefficient \n  # Structure parameteres \n  kfil=k\n  filtre1=width ; filtre2=int(kfil*filtre1) ; filtre3=(kfil*filtre2)  # filters (kernels) per each layer - efic. pe primul \n  nr_conv=3 # 0, 1, 2 sau 3  (number of convolution layers)\n  csize1=3; csize2=3 ; csize3=3      # convolution kernel size (square kernel) \n  psize1=4; psize2=4 ; psize3=4      # pooling size (square)\n  str1=2; str2=2; str3=2             # stride pooling (downsampling rate) \n  pad='same'; # padding style ('valid' is also an alternative)\n  nonlinlayers1=nl[0]  # total of layers (with RELU nonlin) in the first maxpool layer  # De parametrizat asta \n  nonlinlayers2=nl[1]  # \n\n  nonlin_type='relu' # may be other as well 'tanh' 'elu' 'softsign'\n  bndrop=1 # include BatchNorm inainte de MaxPool si drop(0.3) dupa .. \n  cvdrop=1 # droput \n  drop_cv=0.5\n  \n  model = Sequential()\n  # convolution layer1  ==========================================================================\n  # Initially first layer was always a Conv2D one\n  if separ==1:\n    model.add( SeparableConv2D(filtre1, padding=pad, kernel_size=(csize1, csize1), input_shape=input_shape) )\n  elif separ==0: \n    model.add( Conv2D(filtre1, padding=pad, kernel_size=(csize1, csize1), input_shape=input_shape) )\n\n  # next are the additional layers \n  for nl in range(nonlinlayers1-1):\n    model.add(Activation(nonlin_type))  # Activ NL-CNN-1\n    if separ==1:\n      model.add(SeparableConv2D(filtre1, padding=pad, kernel_size=(csize1, csize1) ) ) # Activ NL-CNN-2\n    elif separ==0:\n      model.add(Conv2D(filtre1, padding=pad, kernel_size=(csize1, csize1)) ) # Activ NL-CNN-2\n  #  MaxPool in the end of the module \n  if bndrop==1:\n    model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(psize1, psize1),strides=(str1,str1),padding=pad))\n  if cvdrop==1:\n    model.add(Dropout(drop_cv))\n  \n  # NL LAYER 2 =======================================================================================================\n \n  if separ==1:\n    model.add(SeparableConv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) )\n  elif separ==0:\n    model.add(Conv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) )\n  # aici se adauga un neliniar \n    \n  #=========== unul extra NL=2 pe strat 2 =====================\n  for nl in range(nonlinlayers2-1):\n    model.add(Activation(nonlin_type))  # Activ NL-CNN-1\n    if separ==1:\n        model.add(SeparableConv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) ) # Activ NL-CNN-2\n    elif separ==0:\n        model.add(Conv2D(filtre2, padding=pad, kernel_size=(csize2, csize2)) ) # Activ NL-CNN-2\n        \n  # OUTPUT OF LAYER 2 (MAX-POOL)\n  if bndrop==1:\n      model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(psize2, psize2),strides=(str2,str2),padding=pad))\n  if cvdrop==1:\n      model.add(Dropout(drop_cv))\n  #-------------------------------------------------------------------------------------------\n  # LAYER 3 \n      \n  if separ==1:\n      model.add(SeparableConv2D(filtre3, padding=pad, kernel_size=(csize3, csize3)) )  # SeparableConv\n  elif separ==0:\n      model.add(Conv2D(filtre3, padding=pad, kernel_size=(csize3, csize3)) ) # Activ NL-CNN-2\n  # OUTPUT OF LAYER 3 \n  if bndrop==1:\n      model.add(BatchNormalization())\n  model.add(MaxPooling2D(pool_size=(psize3, psize3),strides=(str3,str3),padding=pad))\n  if cvdrop==1:\n      model.add(Dropout(drop_cv))\n  #------------------- \n  # \n  # LAYER 4  (only if requested - for large images ?? )\n  if add_layer==1:    \n    if separ==1:\n      model.add(SeparableConv2D(1.2*filtre3, padding=pad, kernel_size=(csize3, csize3)) )  # SeparableConv\n    elif separ==0:\n      model.add(Conv2D(1.2*filtre3, padding=pad, kernel_size=(csize3, csize3)) ) # Activ NL-CNN-2\n    # OUTPUT OF LAYER 4\n    if bndrop==1:\n      model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(psize3, psize3),strides=(str3,str3),padding=pad))\n    if cvdrop==1:\n      model.add(Dropout(drop_cv))\n  #========================================================================================\n  # INPUT TO DENSE LAYER (FLATTEN - more data can overfit / GLOBAL - less data - may be a good choice ) \n  if flat==1:\n      model.add(Flatten())  # \n  elif flat==0:\n      model.add(GlobalAveragePooling2D()) # Global average \n   \n  model.add(Dense(num_classes, activation='softmax'))\n  # END OF MODEL DESCRIPTION \n  # ------------------ COMPILE THE MODEL\n  myopt = Adam()\n  #myopt = Nadam()\n  if separ==1:\n    myopt = RMSprop(lr=0.01) \n    #myopt = Adam(lr=0.05)\n\n  # --------------------------   LOSS function  ------------------------------------\n  my_loss='categorical_crossentropy'\n  model.compile(loss=my_loss, \n              optimizer=myopt,   \n              metrics=['accuracy'])\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2024-06-05T01:36:39.245475Z","iopub.execute_input":"2024-06-05T01:36:39.245874Z","iopub.status.idle":"2024-06-05T01:36:39.273805Z","shell.execute_reply.started":"2024-06-05T01:36:39.245843Z","shell.execute_reply":"2024-06-05T01:36:39.272694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Instantiere model NL-CNN","metadata":{}},{"cell_type":"code","source":"k=2; separ=0; flat=1; width=40; nl=(2,2)\nmodel = create_nl_cnn_model(input_shape, num_classes, k, separ, flat, width, nl, add_layer=0)\nmodel_name='NLCNN_'+str(k)+'_'+str(separ)+'_'+str(flat)+'_'+str(width)+'_'+str(nl)\nprint(model_name)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T01:36:43.220036Z","iopub.execute_input":"2024-06-05T01:36:43.221089Z","iopub.status.idle":"2024-06-05T01:36:43.486162Z","shell.execute_reply.started":"2024-06-05T01:36:43.221051Z","shell.execute_reply":"2024-06-05T01:36:43.484985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNETV2 MODEL","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Activation, Input\n\ndef create_model():\n    pretrained_model = tf.keras.applications.MobileNetV2(alpha=0.35, weights='imagenet', include_top=False ,input_shape=[imsize, imsize, 3])\n    pretrained_model.trainable = True # tramsfer learning\n    \n    model = tf.keras.Sequential([\n        pretrained_model,\n        GlobalAveragePooling2D(),\n        Dense(num_classes, activation='softmax')\n    ])\n    model.build()\n    model.compile(\n        optimizer='adam',\n        loss = 'categorical_crossentropy',\n        metrics=['accuracy']\n     )\n    return model\n\nmodel = create_model()\nmodel_name = 'MobileNetV2'\nprint(model_name)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:12:59.973530Z","iopub.execute_input":"2024-06-05T02:12:59.973935Z","iopub.status.idle":"2024-06-05T02:13:01.738038Z","shell.execute_reply.started":"2024-06-05T02:12:59.973904Z","shell.execute_reply":"2024-06-05T02:13:01.736938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANTRENARE MODELE","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nimport time as ti\ncheckpoint = ModelCheckpoint('best_model.keras', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:13:04.854544Z","iopub.execute_input":"2024-06-05T02:13:04.854951Z","iopub.status.idle":"2024-06-05T02:13:04.860629Z","shell.execute_reply.started":"2024-06-05T02:13:04.854917Z","shell.execute_reply":"2024-06-05T02:13:04.859496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoci=250\n\nt1=ti.time()\n\n# doua strategii in functie de cum s-au creat datele (cea fara datagen e in general mai rapida \n# dar necesita memorie RAM suficienta)\nif datagen:\n  history = model.fit(train_generator, epochs=epoci, validation_data=validation_generator, verbose=1,\n                    callbacks = checkpoint)\nelse: \n  history = model.fit(x_train, y_train, epochs=epoci, validation_data=(x_test, y_test), batch_size=batch_size, verbose=1,\n                    callbacks = checkpoint)\n    \nt2=ti.time()\nprint('====================================================')\nprint('Training with  ',epoci,' epochs, lasted  ',int(t2-t1)/60,' minutes')\n\nmodel=load_model('best_model.keras')\nbp=model.get_weights()  # best weights set\nt1=ti.time()\nif datagen:\n    score = model.evaluate(validation_generator, verbose=0)\nelse:\n    score = model.evaluate(x_test, y_test, verbose=0)\nt2=ti.time()\n\nprint('--------------  Raport rulare ------------------------')\nprint ('Marime model (parametri): ',model.count_params())\nprint('Cea mai buna acuratete pe set validare :', 100*score[1],'%')\nprint ('Timp predictie pe tot setul de test: ',t2-t1)\nprint('Set date: ',dataset)\nprint('Model: ',model_name)\nprint('Dimensiune imagine: ',imsize)\nprint('Batch size: ', batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:13:09.500204Z","iopub.execute_input":"2024-06-05T02:13:09.500628Z","iopub.status.idle":"2024-06-05T02:34:09.114437Z","shell.execute_reply.started":"2024-06-05T02:13:09.500593Z","shell.execute_reply":"2024-06-05T02:34:09.113029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:46:59.866531Z","iopub.execute_input":"2024-06-05T02:46:59.867571Z","iopub.status.idle":"2024-06-05T02:46:59.872151Z","shell.execute_reply.started":"2024-06-05T02:46:59.867532Z","shell.execute_reply":"2024-06-05T02:46:59.871116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Salvare modele ","metadata":{}},{"cell_type":"code","source":"file_name = 'best_model.keras'\n#new_name = f\"6__VCNN_model__{int(score[1] * 10000)}.keras\"\n#new_name = f\"6__NLCNN_model__{int(score[1] * 10000)}.keras\"\n#new_name = f\"6__MobileNetV2_model__{int(score[1] * 10000)}.keras\"\n#new_name = f\"4__VCNN_model__{int(score[1] * 10000)}.keras\"\n#new_name = f\"4__NLCNN_model__{int(score[1] * 10000)}.keras\"\nnew_name = f\"4__MobileNetV2_model__{int(score[1] * 10000)}.keras\"\nos.rename(file_name, new_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:48:17.103816Z","iopub.execute_input":"2024-06-05T02:48:17.104786Z","iopub.status.idle":"2024-06-05T02:48:17.110480Z","shell.execute_reply.started":"2024-06-05T02:48:17.104738Z","shell.execute_reply":"2024-06-05T02:48:17.109481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reprezentare grafica","metadata":{}},{"cell_type":"code","source":"# Afișarea evolutiei acuratetii pe set validare (test)\nplt.plot(history.history['accuracy'], label='Accuracy on Training Set')\nplt.plot(history.history['val_accuracy'], label='Accuracy on Validation Set')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n# Afișarea evolutiei functiei obiectiv eroare cumulata (loss)\nplt.plot(history.history['loss'], label='Loss on Training Set')\nplt.plot(history.history['val_loss'], label='Loss on Validation Set')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:48:41.626889Z","iopub.execute_input":"2024-06-05T02:48:41.627841Z","iopub.status.idle":"2024-06-05T02:48:42.134982Z","shell.execute_reply.started":"2024-06-05T02:48:41.627804Z","shell.execute_reply":"2024-06-05T02:48:42.133870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Matricea de confuzie","metadata":{}},{"cell_type":"code","source":"# Loading the Lowest validation loss Model \n#model = load_model('6__VCNN_model__8397.keras')\n#model = load_model('6__NLCNN_model__9152.keras')\n#model = load_model('6__MobileNetV2_model__9098.keras')\n#model = load_model('4__VCNN_model__9420.keras')\n#model = load_model('4__NLCNN_model__9494.keras')\nmodel = load_model('4__MobileNetV2_model__9551.keras')\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nif datagen:\n    \n    # redefinire batch_size=intregul pachet de date (609 aici) deaorece altfel\n    # matricea de confuzie s-ar calcula numai pe un pachet \"batch_size =16\" si este irelevanta\n    test_generator.reset()\n    test_generator = test_datagen.flow_from_directory(directory= root_dir+\"/test\", target_size=(imsize, imsize), batch_size=609, class_mode = 'categorical')\n\n    #val_data.reset()\n    t1=ti.time()\n    accuracy = model.evaluate(test_generator, batch_size=609)[1] \n    t2=ti.time()\n    print(f\"Acuratete set test = {accuracy*100} %\")\n    print ('Martime model (parametri): ',model.count_params())\n    print('Latenta per intreg set test: ', 1000*(t2-t1), 'mili seconds')\n    print('Latenta per sample: ', 1000*(t2-t1)/(609), 'mili seconds')\n\n    for i,j in test_generator:\n        print(i.shape, j.shape)\n        p = model.predict(i)\n        p = p.argmax(-1)\n        t = j.argmax(-1)\n        print(classification_report(t,p))\n        print(confusion_matrix(t,p))\n        break;\nelse:\n    \n   # Confusion matrix and more specific performance indicators\n    #----------------------------------------------------------------\n\n    labels=(np.dot(y_test,np.array(range(num_classes)).T)).astype('int16')\n    pred= model.predict(x_test)\n    predicted_class_indices=np.argmax(pred,axis=1)\n\n    C=confusion_matrix(predicted_class_indices,labels)\n    print (C)\n    print('Classification Report')\n    print(classification_report(labels,predicted_class_indices ))\n ","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:49:48.601629Z","iopub.execute_input":"2024-06-05T02:49:48.602689Z","iopub.status.idle":"2024-06-05T02:49:58.006679Z","shell.execute_reply.started":"2024-06-05T02:49:48.602651Z","shell.execute_reply":"2024-06-05T02:49:58.005487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testarea","metadata":{}},{"cell_type":"code","source":"selectia=int(np.shape(x_test)[0]*np.random.rand(1)[0])  #\n\nimg1=x_test[selectia,:,:,:]\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nif np.shape(x_train)[3]==1:\n  plt.imshow(img1[:,:,0],cmap='gray')\nelif np.shape(x_train)[3]==3:\n  plt.imshow(img1)\n\nlabel=np.dot(y_test[selectia,:],1+np.array(range(num_classes)).T)\nprint('Labeled class :', label-1)\nz=model.predict(x_test[selectia:selectia+1,:,:,:])\nprint('Recognized class  : ',np.argmax(z))","metadata":{"execution":{"iopub.status.busy":"2024-06-05T02:52:44.291829Z","iopub.execute_input":"2024-06-05T02:52:44.292673Z","iopub.status.idle":"2024-06-05T02:52:44.682927Z","shell.execute_reply.started":"2024-06-05T02:52:44.292639Z","shell.execute_reply":"2024-06-05T02:52:44.681835Z"},"trusted":true},"execution_count":null,"outputs":[]}]}